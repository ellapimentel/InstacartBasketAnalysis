{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/X_train.csv')\n",
    "y_train = pd.read_csv('data/y_train.csv')\n",
    "X_test = pd.read_csv('data/X_test.csv')\n",
    "y_test = pd.read_csv('data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test = y_test.values.reshape(-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 : Logistic Regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8823246900289554\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "print(metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: Logistic Regression\n",
      "[[173128   1656]\n",
      " [ 49063 207161]]\n",
      "Classification Report: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87    174784\n",
      "           1       0.99      0.81      0.89    256224\n",
      "\n",
      "    accuracy                           0.88    431008\n",
      "   macro avg       0.89      0.90      0.88    431008\n",
      "weighted avg       0.91      0.88      0.88    431008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix: Logistic Regression\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Classification Report: Logistic Regression\")\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though Precision score for 1's is high, accuracy is still at 88.23% which means that our model has room for improvement. Overall the model is still performing moderately well for a first pass. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Randomized CV Search on Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features=None,\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    presort='deprecated',\n",
       "                                                    random_state=None,\n",
       "                                                    splitter='best'),\n",
       "                   i...\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                                        'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1a26e92410>,\n",
       "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1a26e92490>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "params = {\"max_depth\": np.arange(3,15),\n",
    "              \"max_features\": randint(1, 6),\n",
    "              \"min_samples_leaf\": randint(1, 6),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_cv = RandomizedSearchCV(tree, params, cv=5)\n",
    "tree_cv.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': 14, 'max_features': 5, 'min_samples_leaf': 4}\n",
      "Best score is 0.9487024103334815\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion = 'entropy', max_depth=14, max_features=5, min_samples_leaf= 4)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9535971490088351\n",
      "Balanced accuracy: 0.9601705950623258\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.95    174784\n",
      "           1       1.00      0.93      0.96    256224\n",
      "\n",
      "    accuracy                           0.95    431008\n",
      "   macro avg       0.95      0.96      0.95    431008\n",
      "weighted avg       0.96      0.95      0.95    431008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test,y_pred))\n",
    "print(\"Balanced accuracy:\", metrics.balanced_accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report: \" )\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a RandomizedSearchCV on a Decision Tree Classifier greatly increased the accuracy score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 : Gradient Boosting \n",
    "\n",
    "First I will try without a RandomizedSearchCV and then will try again to see if I can improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=20, learning_rate=1, max_features=2,max_depth=2, random_state=0)\n",
    "gbc.fit(X_train, y_train)\n",
    "y_pred = gbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training) is 0.9434637389450816\n",
      "Accuracy score (test) is 0.9428688098596778\n",
      "Accuracy Score is 0.9428688098596778\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score (training) is ' + str(gbc.score(X_train, y_train)))\n",
    "print('Accuracy score (test) is ' + str(gbc.score(X_test, y_test)))\n",
    "print('Accuracy Score is ' + str(metrics.accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[174196    588]\n",
      " [ 24036 232188]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93    174784\n",
      "           1       1.00      0.91      0.95    256224\n",
      "\n",
      "    accuracy                           0.94    431008\n",
      "   macro avg       0.94      0.95      0.94    431008\n",
      "weighted avg       0.95      0.94      0.94    431008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even without a RandomizedSearchCV the Gradient Boosting model is comparable to the previous Decision Tree Classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                                        criterion='friedman_mse',\n",
       "                                                        init=None,\n",
       "                                                        learning_rate=0.1,\n",
       "                                                        loss='deviance',\n",
       "                                                        max_depth=3,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        n_estimators=100,\n",
       "                                                        n_ite...\n",
       "                                        'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                                        'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1a2b67a510>,\n",
       "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1a2b72a390>,\n",
       "                                        'n_estimators': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = { 'learning_rate': [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1], \"max_features\": randint(1, 6),\n",
    "              \"min_samples_leaf\": randint(1, 6), 'n_estimators': np.arange(1,20), 'max_depth' : np.arange(1,15) }\n",
    "gbc = GradientBoostingClassifier(random_state= 0)\n",
    "gbc_cv = RandomizedSearchCV(gbc, params, cv=5)\n",
    "gbc_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Parameters: {'learning_rate': 0.75, 'max_depth': 14, 'max_features': 2, 'min_samples_leaf': 2, 'n_estimators': 9}\n",
      "Best score is 0.9804561673378253\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Gradient Parameters: {}\".format(gbc_cv.best_params_))\n",
    "print(\"Best score is {}\".format(gbc_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=9, learning_rate=.75, \n",
    "                                 max_features=2,max_depth=14, random_state=0,\n",
    "                                 min_samples_leaf= 2)\n",
    "gbc.fit(X_train, y_train)\n",
    "y_pred = gbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training) is 0.982789526576488\n",
      "Accuracy score (test) is 0.9811882842081817\n",
      "Accuracy Score is 0.9811882842081817\n",
      "Confusion Matrix:\n",
      "[[174441    343]\n",
      " [  7765 248459]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    174784\n",
      "           1       1.00      0.97      0.98    256224\n",
      "\n",
      "    accuracy                           0.98    431008\n",
      "   macro avg       0.98      0.98      0.98    431008\n",
      "weighted avg       0.98      0.98      0.98    431008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score (training) is ' + str(gbc.score(X_train, y_train)))\n",
    "print('Accuracy score (test) is ' + str(gbc.score(X_test, y_test)))\n",
    "print('Accuracy Score is ' + str(metrics.accuracy_score(y_pred, y_test)))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another bump in accuracy from tuning the hyperparameters on our Gradient Boosting Classifier. Since it is predicting with 98% accuracy and an F1 score of .98, this will be the model I will use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
